# main.py
"""
Enhanced libclang C Parser API - ãƒªãƒƒãƒãªASTè§£æç‰ˆ
Cè¨€èªã‚³ãƒ¼ãƒ‰ã®è§£æçµæœã‚’ã‚ˆã‚Šè©³ç´°ã«å–å¾—ã§ãã‚‹API
ãƒ«ãƒ¼ãƒ—çµ‚äº†ä½ç½®ã®æ­£ç¢ºãªæ¤œå‡ºã€é–¢æ•°ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã€å¤‰æ•°ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç­‰ã‚’å«ã‚€
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import clang.cindex
from clang.cindex import CursorKind, TypeKind, TokenKind
import tempfile
import os
import re
from typing import Dict, List, Any, Optional, Set
import subprocess

# Flaskã‚¢ãƒ—ãƒªåˆæœŸåŒ–
app = Flask(__name__)
CORS(app)  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯

# ================================
# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹å®šç¾©ï¼ˆç°¡ç•¥ç‰ˆï¼šdataclassã‚’ä½¿ã‚ãšã«è¾æ›¸ã§ï¼‰
# ================================

def create_loop_info(start_line, end_line, **kwargs):
    """ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚’ä½œæˆ"""
    return {
        "start_line": start_line,
        "end_line": end_line,
        "body_start_line": kwargs.get("body_start_line"),
        "body_end_line": kwargs.get("body_end_line"),
        "condition_line": kwargs.get("condition_line"),
        "increment_line": kwargs.get("increment_line"),
        "nested_level": kwargs.get("nested_level", 0),
        "has_break": kwargs.get("has_break", False),
        "has_continue": kwargs.get("has_continue", False),
        "estimated_complexity": kwargs.get("estimated_complexity", "unknown")
    }

def create_function_info(**kwargs):
    """é–¢æ•°æƒ…å ±ã‚’ä½œæˆ"""
    return {
        "complexity_score": kwargs.get("complexity_score", 0),
        "max_nesting_depth": kwargs.get("max_nesting_depth", 0),
        "parameter_count": kwargs.get("parameter_count", 0),
        "local_variable_count": kwargs.get("local_variable_count", 0),
        "calls_functions": kwargs.get("calls_functions", []),
        "return_points": kwargs.get("return_points", []),
        "memory_operations": kwargs.get("memory_operations", {"allocations": [], "deallocations": []})
    }

def create_variable_info(scope_start_line, scope_end_line, **kwargs):
    """å¤‰æ•°æƒ…å ±ã‚’ä½œæˆ"""
    return {
        "scope_start_line": scope_start_line,
        "scope_end_line": scope_end_line,
        "usage_locations": kwargs.get("usage_locations", []),
        "modification_locations": kwargs.get("modification_locations", []),
        "is_initialized": kwargs.get("is_initialized", False),
        "initialization_line": kwargs.get("initialization_line"),
        "data_flow": kwargs.get("data_flow", [])
    }

def create_control_flow_info(**kwargs):
    """åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼æƒ…å ±ã‚’ä½œæˆ"""
    return {
        "condition_complexity": kwargs.get("condition_complexity", "simple"),
        "has_else": kwargs.get("has_else", False),
        "else_if_chain_length": kwargs.get("else_if_chain_length", 0),
        "branches": kwargs.get("branches", [])
    }

# ================================
# libclangè‡ªå‹•æ¤œå‡º
# ================================

def find_libclang():
    """libclangãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ‘ã‚¹ã‚’è‡ªå‹•æ¤œå‡º"""
    possible_paths = [
        '/usr/lib/x86_64-linux-gnu/libclang-1.so',
        '/usr/lib/libclang.so',
        '/usr/lib/libclang-16.so',
        '/usr/lib/x86_64-linux-gnu/libclang.so',
        '/usr/lib/x86_64-linux-gnu/libclang-16.so',
        '/usr/local/lib/libclang.so',
    ]
    
    # å„ãƒ‘ã‚¹ã‚’è©¦ã™
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    # ldconfigã§æ¤œç´¢
    try:
        result = subprocess.run(['ldconfig', '-p'], capture_output=True, text=True)
        for line in result.stdout.split('\n'):
            if 'libclang' in line:
                parts = line.split(' => ')
                if len(parts) > 1:
                    return parts[1].strip()
    except:
        pass
    
    # æœ€å¾Œã®æ‰‹æ®µ: find ã‚³ãƒãƒ³ãƒ‰
    try:
        result = subprocess.run(['find', '/usr', '-name', 'libclang*.so*', '-type', 'f'], 
                              capture_output=True, text=True, timeout=10)
        lines = result.stdout.strip().split('\n')
        if lines and lines[0]:
            return lines[0]
    except:
        pass
    
    return None

# libclangãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’è‡ªå‹•æ¤œå‡ºã—ã¦è¨­å®š
libclang_path = find_libclang()
if libclang_path:
    print(f"ğŸ” Found libclang at: {libclang_path}")
    clang.cindex.conf.set_library_file(libclang_path)
else:
    print("âš ï¸  libclang not found, trying default configuration")

# ================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ================================

def create_temp_file(code):
    """Cè¨€èªã‚³ãƒ¼ãƒ‰ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.c', delete=False)
    temp_file.write(code)
    temp_file.close()
    return temp_file.name

def parse_with_libclang(code):
    """libclangã§Cè¨€èªã‚³ãƒ¼ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹"""
    index = clang.cindex.Index.create()
    temp_path = create_temp_file(code)
    
    try:
        translation_unit = index.parse(temp_path)
        return translation_unit, temp_path
    except Exception as e:
        if os.path.exists(temp_path):
            os.unlink(temp_path)
        raise e

def cleanup_temp_file(temp_path):
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    if os.path.exists(temp_path):
        os.unlink(temp_path)

def validate_request():
    """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    if not request.is_json:
        return None, jsonify({"success": False, "error": "Content-Type must be application/json"}), 400
    
    data = request.get_json()
    if not data or 'code' not in data:
        return None, jsonify({"success": False, "error": "Missing 'code' field"}), 400
    
    code = data['code']
    if not isinstance(code, str):
        return None, jsonify({"success": False, "error": "'code' must be string"}), 400
    
    return code, None, None

# ================================
# ãƒªãƒƒãƒãªè§£æé–¢æ•°ç¾¤
# ================================

def get_precise_extent_info(cursor):
    """ã‚«ãƒ¼ã‚½ãƒ«ã®æ­£ç¢ºãªç¯„å›²æƒ…å ±ã‚’å–å¾—"""
    extent = cursor.extent
    start_location = extent.start
    end_location = extent.end
    
    return {
        "start_line": start_location.line,
        "start_column": start_location.column,
        "end_line": end_location.line,
        "end_column": end_location.column
    }

def analyze_loop_structure(cursor, nesting_level=0):
    """ãƒ«ãƒ¼ãƒ—æ§‹é€ ã®è©³ç´°åˆ†æ"""
    if cursor.kind not in [CursorKind.FOR_STMT, CursorKind.WHILE_STMT, CursorKind.DO_STMT]:
        return None
    
    extent_info = get_precise_extent_info(cursor)
    
    loop_info = create_loop_info(
        start_line=extent_info["start_line"],
        end_line=extent_info["end_line"],
        nested_level=nesting_level
    )
    
    # å­è¦ç´ ã‚’åˆ†æã—ã¦ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’å–å¾—
    children = list(cursor.get_children())
    
    if cursor.kind == CursorKind.FOR_STMT:
        # FORæ–‡ã®æ§‹é€ : [åˆæœŸåŒ–], [æ¡ä»¶], [å¢—åˆ†], [æœ¬ä½“]
        if len(children) >= 4:
            # æ¡ä»¶éƒ¨åˆ†ã®è¡Œç•ªå·
            condition_cursor = children[1] if len(children) > 1 else None
            if condition_cursor:
                loop_info["condition_line"] = condition_cursor.location.line
            
            # å¢—åˆ†éƒ¨åˆ†ã®è¡Œç•ªå·
            increment_cursor = children[2] if len(children) > 2 else None
            if increment_cursor:
                loop_info["increment_line"] = increment_cursor.location.line
            
            # æœ¬ä½“éƒ¨åˆ†ã®ç¯„å›²
            body_cursor = children[3] if len(children) > 3 else None
            if body_cursor:
                body_extent = get_precise_extent_info(body_cursor)
                loop_info["body_start_line"] = body_extent["start_line"]
                loop_info["body_end_line"] = body_extent["end_line"]
    
    elif cursor.kind == CursorKind.WHILE_STMT:
        # WHILEæ–‡ã®æ§‹é€ : [æ¡ä»¶], [æœ¬ä½“]
        if len(children) >= 2:
            # æ¡ä»¶éƒ¨åˆ†
            condition_cursor = children[0]
            loop_info["condition_line"] = condition_cursor.location.line
            
            # æœ¬ä½“éƒ¨åˆ†
            body_cursor = children[1]
            body_extent = get_precise_extent_info(body_cursor)
            loop_info["body_start_line"] = body_extent["start_line"]
            loop_info["body_end_line"] = body_extent["end_line"]
    
    # ãƒ«ãƒ¼ãƒ—å†…ã®break/continueæ–‡ã‚’æ¤œå‡º
    break_continue_finder = BreakContinueFinder()
    break_continue_finder.visit_cursor(cursor)
    loop_info["has_break"] = break_continue_finder.has_break
    loop_info["has_continue"] = break_continue_finder.has_continue
    
    return loop_info

class BreakContinueFinder:
    """ãƒ«ãƒ¼ãƒ—å†…ã®break/continueæ–‡ã‚’æ¤œå‡ºã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.has_break = False
        self.has_continue = False
    
    def visit_cursor(self, cursor):
        if cursor.kind == CursorKind.BREAK_STMT:
            self.has_break = True
        elif cursor.kind == CursorKind.CONTINUE_STMT:
            self.has_continue = True
        
        # å­è¦ç´ ã‚’å†å¸°çš„ã«æ¢ç´¢ï¼ˆãŸã ã—ã€ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—ã¯é™¤å¤–ï¼‰
        for child in cursor.get_children():
            if child.kind not in [CursorKind.FOR_STMT, CursorKind.WHILE_STMT, CursorKind.DO_STMT]:
                self.visit_cursor(child)

def analyze_function_complexity(cursor):
    """é–¢æ•°ã®è¤‡é›‘åº¦ã‚’åˆ†æ"""
    if cursor.kind != CursorKind.FUNCTION_DECL:
        return None
    
    complexity_analyzer = FunctionComplexityAnalyzer()
    complexity_analyzer.visit_cursor(cursor)
    
    return create_function_info(
        complexity_score=complexity_analyzer.complexity_score,
        max_nesting_depth=complexity_analyzer.max_nesting_depth,
        parameter_count=len([c for c in cursor.get_children() if c.kind == CursorKind.PARM_DECL]),
        local_variable_count=complexity_analyzer.local_var_count,
        calls_functions=complexity_analyzer.function_calls,
        return_points=complexity_analyzer.return_points,
        memory_operations=complexity_analyzer.memory_ops
    )

class FunctionComplexityAnalyzer:
    """é–¢æ•°ã®è¤‡é›‘åº¦ã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.complexity_score = 1
        self.current_nesting_depth = 0
        self.max_nesting_depth = 0
        self.local_var_count = 0
        self.function_calls = []
        self.return_points = []
        self.memory_ops = {"allocations": [], "deallocations": []}
    
    def visit_cursor(self, cursor, depth=0):
        # ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã‚’æ›´æ–°
        if cursor.kind in [CursorKind.IF_STMT, CursorKind.FOR_STMT, CursorKind.WHILE_STMT, 
                          CursorKind.SWITCH_STMT, CursorKind.DO_STMT]:
            depth += 1
            self.complexity_score += 1
            self.max_nesting_depth = max(self.max_nesting_depth, depth)
        
        # ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        if cursor.kind == CursorKind.VAR_DECL:
            self.local_var_count += 1
        
        # é–¢æ•°å‘¼ã³å‡ºã—ã‚’è¨˜éŒ²
        if cursor.kind == CursorKind.CALL_EXPR:
            func_name = cursor.spelling or "unknown"
            if func_name not in self.function_calls:
                self.function_calls.append(func_name)
            
            # ãƒ¡ãƒ¢ãƒªæ“ä½œã‚’ç‰¹åˆ¥ã«è¨˜éŒ²
            if func_name in ['malloc', 'calloc', 'realloc']:
                self.memory_ops["allocations"].append({
                    "line": cursor.location.line,
                    "function": func_name
                })
            elif func_name == 'free':
                self.memory_ops["deallocations"].append({
                    "line": cursor.location.line,
                    "function": func_name
                })
        
        # returnæ–‡ã‚’è¨˜éŒ²
        if cursor.kind == CursorKind.RETURN_STMT:
            self.return_points.append({
                "line": cursor.location.line,
                "type": "normal"
            })
        
        # å­è¦ç´ ã‚’å†å¸°çš„ã«å‡¦ç†
        for child in cursor.get_children():
            self.visit_cursor(child, depth)

def analyze_control_flow(cursor):
    """åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã®è©³ç´°åˆ†æ"""
    if cursor.kind != CursorKind.IF_STMT:
        return None
    
    control_flow = create_control_flow_info()
    
    # å­è¦ç´ ã‚’åˆ†æ
    children = list(cursor.get_children())
    branch_count = 0
    branches = []
    
    for i, child in enumerate(children):
        if child.kind == CursorKind.COMPOUND_STMT:
            branch_count += 1
            branch_info = {
                "type": "if_true" if branch_count == 1 else f"else_branch_{branch_count}",
                "start_line": child.extent.start.line,
                "end_line": child.extent.end.line
            }
            branches.append(branch_info)
        elif child.kind == CursorKind.IF_STMT:
            # else if ã®å ´åˆ
            control_flow["else_if_chain_length"] += 1
    
    control_flow["branches"] = branches
    control_flow["has_else"] = branch_count > 1
    
    return control_flow

def analyze_variable_info(cursor):
    """å¤‰æ•°ã®è©³ç´°æƒ…å ±ã‚’åˆ†æ"""
    if cursor.kind != CursorKind.VAR_DECL:
        return None
    
    return create_variable_info(
        scope_start_line=cursor.location.line,
        scope_end_line=cursor.location.line,
        is_initialized=has_initializer(cursor),
        initialization_line=cursor.location.line if has_initializer(cursor) else None
    )

def has_initializer(cursor):
    """å¤‰æ•°ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    for child in cursor.get_children():
        if child.kind != CursorKind.TYPE_REF:
            return True
    return False

# ================================
# ASTå¤‰æ›é–¢æ•°
# ================================

def enhanced_cursor_to_dict(cursor, nesting_level=0):
    """libclangã®Cursorã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒªãƒƒãƒãªè¾æ›¸å½¢å¼ã«å¤‰æ›"""
    # åŸºæœ¬æƒ…å ±
    result = {
        'kind': cursor.kind.name,
        'spelling': cursor.spelling,
        'type': cursor.type.spelling,
        'location': {
            'line': cursor.location.line,
            'column': cursor.location.column,
            'file': cursor.location.file.name if cursor.location.file else None
        }
    }
    
    # æ­£ç¢ºãªç¯„å›²æƒ…å ±ã‚’è¿½åŠ 
    extent_info = get_precise_extent_info(cursor)
    result['extent'] = extent_info
    
    # ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚’è¿½åŠ 
    tokens = []
    if cursor.extent.start.line != 0 or cursor.extent.end.line != 0:
        try:
            for token in cursor.get_tokens():
                tokens.append({
                    'kind': token.kind.name,
                    'spelling': token.spelling,
                    'location': {
                        'line': token.location.line,
                        'column': token.location.column
                    }
                })
        except Exception as e:
            app.logger.debug(f"Failed to get tokens for cursor {cursor.kind.name}: {e}")
    
    if tokens:
        result['tokens'] = tokens
    
    # ãƒ«ãƒ¼ãƒ—æ§‹é€ ã®è©³ç´°åˆ†æ
    if cursor.kind in [CursorKind.FOR_STMT, CursorKind.WHILE_STMT, CursorKind.DO_STMT]:
        loop_info = analyze_loop_structure(cursor, nesting_level)
        if loop_info:
            result['loop_info'] = loop_info
    
    # é–¢æ•°ã®è©³ç´°åˆ†æ
    if cursor.kind == CursorKind.FUNCTION_DECL:
        result['result_type_spelling'] = cursor.result_type.spelling
        function_info = analyze_function_complexity(cursor)
        if function_info:
            result['function_info'] = function_info
    
    # åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã®åˆ†æ
    if cursor.kind == CursorKind.IF_STMT:
        control_flow_info = analyze_control_flow(cursor)
        if control_flow_info:
            result['control_flow_info'] = control_flow_info
    
    # å¤‰æ•°æƒ…å ±ã®åˆ†æ
    if cursor.kind == CursorKind.VAR_DECL:
        var_info = analyze_variable_info(cursor)
        if var_info:
            result['variable_info'] = var_info
    
    # å­è¦ç´ ã‚’å†å¸°çš„ã«å‡¦ç†
    children = []
    child_nesting = nesting_level
    if cursor.kind in [CursorKind.IF_STMT, CursorKind.FOR_STMT, CursorKind.WHILE_STMT]:
        child_nesting += 1
    
    for child in cursor.get_children():
        children.append(enhanced_cursor_to_dict(child, child_nesting))
    
    if children:
        result['children'] = children
    
    return result

def cursor_to_dict(cursor):
    """å¾“æ¥ã®ASTå¤‰æ›é–¢æ•°ï¼ˆä¸‹ä½äº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰"""
    result = {
        'kind': cursor.kind.name,
        'spelling': cursor.spelling,
        'type': cursor.type.spelling,
        'location': {
            'line': cursor.location.line,
            'column': cursor.location.column,
            'file': cursor.location.file.name if cursor.location.file else None
        }
    }
    
    # extentæƒ…å ±ã‚’è¿½åŠ ï¼ˆãƒ«ãƒ¼ãƒ—çµ‚äº†ä½ç½®æ¤œå‡ºã®ãŸã‚ï¼‰
    extent_info = get_precise_extent_info(cursor)
    result['extent'] = extent_info
    
    # ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚’è¿½åŠ 
    tokens = []
    if cursor.extent.start.line != 0 or cursor.extent.end.line != 0:
        try:
            for token in cursor.get_tokens():
                tokens.append({
                    'kind': token.kind.name,
                    'spelling': token.spelling,
                    'location': {
                        'line': token.location.line,
                        'column': token.location.column
                    }
                })
        except Exception as e:
            app.logger.debug(f"Failed to get tokens for cursor {cursor.kind.name}: {e}")
    
    if tokens:
        result['tokens'] = tokens

    # FUNCTION_DECLã®æˆ»ã‚Šå€¤å‹ã‚’è¿½åŠ 
    if cursor.kind == CursorKind.FUNCTION_DECL:
        result['result_type_spelling'] = cursor.result_type.spelling

    # å­è¦ç´ ã‚’å†å¸°çš„ã«å‡¦ç†
    children = []
    for child in cursor.get_children():
        children.append(cursor_to_dict(child))
    
    if children:
        result['children'] = children
    
    return result

# ================================
# çµ±è¨ˆé–¢æ•°ç¾¤
# ================================

def count_functions(cursor):
    """é–¢æ•°ã®ç·æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
    count = 0
    if cursor.kind == CursorKind.FUNCTION_DECL:
        count += 1
    
    for child in cursor.get_children():
        count += count_functions(child)
    
    return count

def count_loops(cursor):
    """ãƒ«ãƒ¼ãƒ—ã®ç·æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
    count = 0
    if cursor.kind in [CursorKind.FOR_STMT, CursorKind.WHILE_STMT, CursorKind.DO_STMT]:
        count += 1
    
    for child in cursor.get_children():
        count += count_loops(child)
    
    return count

def count_variables(cursor):
    """å¤‰æ•°ã®ç·æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
    count = 0
    if cursor.kind == CursorKind.VAR_DECL:
        count += 1
    
    for child in cursor.get_children():
        count += count_variables(child)
    
    return count

def get_max_nesting_depth(cursor, current_depth=0):
    """æœ€å¤§ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã‚’å–å¾—"""
    max_depth = current_depth
    
    if cursor.kind in [CursorKind.IF_STMT, CursorKind.FOR_STMT, CursorKind.WHILE_STMT, 
                      CursorKind.SWITCH_STMT, CursorKind.DO_STMT]:
        current_depth += 1
    
    for child in cursor.get_children():
        child_max = get_max_nesting_depth(child, current_depth)
        max_depth = max(max_depth, child_max)
    
    return max_depth

def calculate_overall_complexity(cursor):
    """ãƒ—ãƒ­ã‚°ãƒ©ãƒ å…¨ä½“ã®è¤‡é›‘åº¦ã‚’è¨ˆç®—"""
    complexity = 0
    
    def visit_cursor(cursor):
        nonlocal complexity
        if cursor.kind in [CursorKind.IF_STMT, CursorKind.FOR_STMT, CursorKind.WHILE_STMT, 
                          CursorKind.SWITCH_STMT, CursorKind.DO_STMT]:
            complexity += 1
        
        for child in cursor.get_children():
            visit_cursor(child)
    
    visit_cursor(cursor)
    return complexity

# ================================
# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®šç¾©
# ================================

@app.route('/api/enhanced-ast', methods=['POST'])
def get_enhanced_ast():
    """ãƒªãƒƒãƒãªASTè§£æçµæœã‚’å–å¾—"""
    try:
        code, error_response, status_code = validate_request()
        if error_response:
            return error_response, status_code
        
        translation_unit, temp_path = parse_with_libclang(code)
        
        try:
            enhanced_ast = enhanced_cursor_to_dict(translation_unit.cursor)
            
            return jsonify({
                "success": True,
                "enhanced_ast": enhanced_ast,
                "analysis_metadata": {
                    "total_functions": count_functions(translation_unit.cursor),
                    "total_loops": count_loops(translation_unit.cursor),
                    "total_variables": count_variables(translation_unit.cursor),
                    "max_nesting_depth": get_max_nesting_depth(translation_unit.cursor)
                }
            })
            
        finally:
            cleanup_temp_file(temp_path)
            
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/ast', methods=['POST'])
def get_ast():
    """æ§‹æ–‡è§£æçµæœï¼ˆAST: æŠ½è±¡æ§‹æ–‡æœ¨ï¼‰ã‚’å–å¾—"""
    try:
        code, error_response, status_code = validate_request()
        if error_response:
            return error_response, status_code
        
        translation_unit, temp_path = parse_with_libclang(code)
        
        try:
            ast = cursor_to_dict(translation_unit.cursor)
            
            return jsonify({
                "success": True,
                "ast": ast
            })
            
        finally:
            cleanup_temp_file(temp_path)
            
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/tokens', methods=['POST'])
def get_tokens():
    """å­—å¥è§£æçµæœï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã‚’å–å¾—"""
    try:
        code, error_response, status_code = validate_request()
        if error_response:
            return error_response, status_code
        
        translation_unit, temp_path = parse_with_libclang(code)
        
        try:
            tokens = []
            for token in translation_unit.get_tokens(extent=translation_unit.cursor.extent):
                tokens.append({
                    'kind': token.kind.name,
                    'spelling': token.spelling,
                    'location': {
                        'line': token.location.line,
                        'column': token.location.column
                    }
                })
            
            return jsonify({
                "success": True,
                "tokens": tokens
            })
            
        finally:
            cleanup_temp_file(temp_path)
            
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/diagnostics', methods=['POST'])
def get_diagnostics():
    """è¨ºæ–­æƒ…å ±ï¼ˆã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šï¼‰ã‚’å–å¾—"""
    try:
        code, error_response, status_code = validate_request()
        if error_response:
            return error_response, status_code
        
        translation_unit, temp_path = parse_with_libclang(code)
        
        try:
            diagnostics = []
            for diag in translation_unit.diagnostics:
                diagnostics.append({
                    'severity': diag.severity,
                    'spelling': diag.spelling,
                    'location': {
                        'line': diag.location.line,
                        'column': diag.location.column,
                        'file': diag.location.file.name if diag.location.file else None
                    },
            # 4. è¨ºæ–­æƒ…å ±
            for diag in translation_unit.diagnostics:
                result["diagnostics"].append({
                    'severity': diag.severity,
                    'spelling': diag.spelling,
                    'location': {
                        'line': diag.location.line,
                        'column': diag.location.column,
                        'file': diag.location.file.name if diag.location.file else None
                    },
                    'category_name': diag.category_name,
                    'option': diag.option
                })
            
            # 5. ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ãƒ‰æƒ…å ±
            for include in translation_unit.get_includes():
                result["includes"].append({
                    'source': include.source.name if include.source else None,
                    'include': include.include.name if include.include else None,
                    'location': {
                        'line': include.location.line,
                        'column': include.location.column
                    },
                    'depth': include.depth
                })
            
            # 6. è§£æã‚µãƒãƒªãƒ¼æƒ…å ±
            result["analysis_summary"] = {
                "total_functions": count_functions(translation_unit.cursor),
                "total_loops": count_loops(translation_unit.cursor),
                "total_variables": count_variables(translation_unit.cursor),
                "max_nesting_depth": get_max_nesting_depth(translation_unit.cursor),
                "total_tokens": len(result["tokens"]),
                "has_errors": len(result["diagnostics"]) > 0,
                "complexity_score": calculate_overall_complexity(translation_unit.cursor)
            }
            
            return jsonify(result)
            
        finally:
            cleanup_temp_file(temp_path)
            
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/loop-analysis', methods=['POST'])
def get_loop_analysis():
    """ãƒ«ãƒ¼ãƒ—æ§‹é€ å°‚ç”¨ã®è©³ç´°åˆ†æ"""
    try:
        code, error_response, status_code = validate_request()
        if error_response:
            return error_response, status_code
        
        translation_unit, temp_path = parse_with_libclang(code)
        
        try:
            loops = []
            loop_finder = LoopFinder()
            loop_finder.visit_cursor(translation_unit.cursor)
            
            for loop_cursor in loop_finder.loops:
                loop_info = analyze_loop_structure(loop_cursor)
                if loop_info:
                    loop_data = {
                        "cursor_info": {
                            "kind": loop_cursor.kind.name,
                            "location": {
                                "line": loop_cursor.location.line,
                                "column": loop_cursor.location.column
                            }
                        },
                        "loop_details": loop_info,
                        "source_text": get_source_text(loop_cursor, code)
                    }
                    loops.append(loop_data)
            
            return jsonify({
                "success": True,
                "loops": loops,
                "loop_count": len(loops),
                "analysis_metadata": {
                    "nested_loops": count_nested_loops(translation_unit.cursor),
                    "infinite_loop_warnings": detect_potential_infinite_loops(loops)
                }
            })
            
        finally:
            cleanup_temp_file(temp_path)
            
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

# ================================
# è¿½åŠ ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°
# ================================

class LoopFinder:
    """ãƒ«ãƒ¼ãƒ—ã‚’æ¤œå‡ºã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.loops = []
    
    def visit_cursor(self, cursor):
        if cursor.kind in [CursorKind.FOR_STMT, CursorKind.WHILE_STMT, CursorKind.DO_STMT]:
            self.loops.append(cursor)
        
        for child in cursor.get_children():
            self.visit_cursor(child)

def get_source_text(cursor, original_code):
    """ã‚«ãƒ¼ã‚½ãƒ«ã«å¯¾å¿œã™ã‚‹ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    try:
        lines = original_code.split('\n')
        start_line = cursor.extent.start.line - 1
        end_line = cursor.extent.end.line - 1
        
        if start_line == end_line:
            # å˜ä¸€è¡Œã®å ´åˆ
            if start_line < len(lines):
                line = lines[start_line]
                start_col = cursor.extent.start.column - 1
                end_col = cursor.extent.end.column - 1
                return line[start_col:end_col]
        else:
            # è¤‡æ•°è¡Œã®å ´åˆ
            if start_line < len(lines) and end_line < len(lines):
                result_lines = []
                for i in range(start_line, end_line + 1):
                    if i == start_line:
                        # æœ€åˆã®è¡Œ
                        start_col = cursor.extent.start.column - 1
                        result_lines.append(lines[i][start_col:])
                    elif i == end_line:
                        # æœ€å¾Œã®è¡Œ
                        end_col = cursor.extent.end.column - 1
                        result_lines.append(lines[i][:end_col])
                    else:
                        # ä¸­é–“ã®è¡Œ
                        result_lines.append(lines[i])
                return '\n'.join(result_lines)
    except Exception as e:
        app.logger.debug(f"Failed to extract source text: {e}")
    
    return "unable to extract"

def count_nested_loops(cursor, in_loop=False):
    """ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
    nested_count = 0
    current_is_loop = cursor.kind in [CursorKind.FOR_STMT, CursorKind.WHILE_STMT, CursorKind.DO_STMT]
    
    if current_is_loop and in_loop:
        nested_count += 1
    
    for child in cursor.get_children():
        nested_count += count_nested_loops(child, in_loop or current_is_loop)
    
    return nested_count

def detect_potential_infinite_loops(loops):
    """ç„¡é™ãƒ«ãƒ¼ãƒ—ã®å¯èƒ½æ€§ã‚’æ¤œå‡º"""
    warnings = []
    
    for loop_data in loops:
        loop_info = loop_data.get("loop_details", {})
        
        # ç°¡æ˜“çš„ãªç„¡é™ãƒ«ãƒ¼ãƒ—æ¤œå‡º
        if (not loop_info.get("has_break", False) and 
            not loop_info.get("has_continue", False) and
            loop_data["cursor_info"]["kind"] == "WHILE_STMT"):
            warnings.append({
                "line": loop_data["cursor_info"]["location"]["line"],
                "type": "potential_infinite_loop",
                "message": "WHILE loop without break statement detected"
            })
    
    return warnings

# ================================
# APIæƒ…å ±ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ================================

@app.route('/', methods=['GET'])
def api_info():
    """API ã®ä½¿ç”¨æ–¹æ³•ã‚’è¡¨ç¤º"""
    return jsonify({
        "name": "Enhanced libclang C Parser API",
        "version": "2.0.0",
        "description": "Cè¨€èªã‚³ãƒ¼ãƒ‰ã®ãƒªãƒƒãƒãªè§£æçµæœã‚’å–å¾—ã§ãã‚‹APIï¼ˆãƒ«ãƒ¼ãƒ—çµ‚äº†ä½ç½®ã€é–¢æ•°è¤‡é›‘åº¦ç­‰ã‚’å«ã‚€ï¼‰",
        "endpoints": {
            "POST /api/tokens": "å­—å¥è§£æçµæœï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã‚’å–å¾—",
            "POST /api/ast": "æ§‹æ–‡è§£æçµæœï¼ˆå¾“æ¥ã®ASTï¼‰ã‚’å–å¾—",
            "POST /api/enhanced-ast": "ãƒªãƒƒãƒãªASTè§£æçµæœã‚’å–å¾—ï¼ˆæ¨å¥¨ï¼‰",
            "POST /api/loop-analysis": "ãƒ«ãƒ¼ãƒ—æ§‹é€ å°‚ç”¨ã®è©³ç´°åˆ†æ",
            "POST /api/diagnostics": "è¨ºæ–­æƒ…å ±ï¼ˆã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šï¼‰ã‚’å–å¾—", 
            "POST /api/includes": "ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—",
            "POST /api/all": "å…¨ã¦ã®è§£æçµæœã‚’ã¾ã¨ã‚ã¦å–å¾—ï¼ˆæ‹¡å¼µç‰ˆï¼‰"
        },
        "new_features": {
            "loop_end_detection": "ãƒ«ãƒ¼ãƒ—ã®æ­£ç¢ºãªçµ‚äº†ä½ç½®ã‚’æ¤œå‡º",
            "function_complexity": "é–¢æ•°ã®è¤‡é›‘åº¦åˆ†æ",
            "control_flow_analysis": "åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã®è©³ç´°åˆ†æ",
            "variable_lifecycle": "å¤‰æ•°ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«è¿½è·¡",
            "memory_operation_tracking": "ãƒ¡ãƒ¢ãƒªæ“ä½œã®è¿½è·¡",
            "nesting_depth_analysis": "ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã®åˆ†æ"
        },
        "request_format": {
            "code": "string (required) - Cè¨€èªã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰"
        },
        "enhanced_example": {
            "url": "/api/enhanced-ast",
            "method": "POST",
            "body": {"code": "int main() { for(int i=0; i<10; i++) { printf(\"%d\", i); } return 0; }"},
            "response_includes": [
                "precise loop end positions",
                "function complexity metrics", 
                "variable scope information",
                "control flow analysis"
            ]
        }
    })

# ================================
# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
# ================================

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    
    print("ğŸš€ Enhanced libclang C Parser API v2.0")
    print(f"   Port: {port}")
    print("ğŸ“ Available endpoints:")
    print("   GET  / - API information")
    print("   POST /api/tokens - Get lexical analysis results")
    print("   POST /api/ast - Get syntax analysis results (legacy)")  
    print("   POST /api/enhanced-ast - Get rich AST analysis results (NEW)")
    print("   POST /api/loop-analysis - Get detailed loop structure analysis (NEW)")
    print("   POST /api/diagnostics - Get error/warning diagnostics")
    print("   POST /api/includes - Get include information")
    print("   POST /api/all - Get all analysis results (enhanced)")
    print("\nğŸ¯ New Features:")
    print("   âœ… Precise loop end position detection")
    print("   âœ… Function complexity analysis")
    print("   âœ… Control flow detailed analysis")
    print("   âœ… Variable lifecycle tracking")
    print("   âœ… Memory operation tracking")
    print("   âœ… Nesting depth analysis")
    
    # æœ¬ç•ªç’°å¢ƒã§ã¯gunicornãŒæ¨å¥¨ã ãŒã€é–‹ç™ºæ™‚ã¯Flaské–‹ç™ºã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨
    if os.environ.get('FLASK_ENV') == 'development':
        app.run(host='0.0.0.0', port=port, debug=True)
    else:
        # æœ¬ç•ªç’°å¢ƒ: gunicornã§èµ·å‹•ã•ã‚Œã‚‹ï¼ˆDockerfileã§æŒ‡å®šï¼‰
        # ç›´æ¥å®Ÿè¡Œæ™‚ã¯Flaské–‹ç™ºã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨
        app.run(host='0.0.0.0', port=port, debug=False)ag.category_name,
                    'option': diag.option
                })
            
            return jsonify({
                "success": True,
                "diagnostics": diagnostics
            })
            
        finally:
            cleanup_temp_file(temp_path)
            
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/includes', methods=['POST'])
def get_includes():
    """ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—"""
    try:
        code, error_response, status_code = validate_request()
        if error_response:
            return error_response, status_code
        
        translation_unit, temp_path = parse_with_libclang(code)
        
        try:
            includes = []
            for include in translation_unit.get_includes():
                includes.append({
                    'source': include.source.name if include.source else None,
                    'include': include.include.name if include.include else None,
                    'location': {
                        'line': include.location.line,
                        'column': include.location.column
                    },
                    'depth': include.depth
                })
            
            return jsonify({
                "success": True,
                "includes": includes
            })
            
        finally:
            cleanup_temp_file(temp_path)
            
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/all', methods=['POST'])
def get_all():
    """å…¨ã¦ã®è§£æçµæœã‚’ã¾ã¨ã‚ã¦å–å¾—ï¼ˆæ‹¡å¼µç‰ˆï¼‰"""
    try:
        code, error_response, status_code = validate_request()
        if error_response:
            return error_response, status_code
        
        translation_unit, temp_path = parse_with_libclang(code)
        
        try:
            result = {
                "success": True,
                "tokens": [],
                "ast": {},
                "enhanced_ast": {},
                "diagnostics": [],
                "includes": [],
                "analysis_summary": {}
            }
            
            # 1. ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±
            for token in translation_unit.get_tokens(extent=translation_unit.cursor.extent):
                result["tokens"].append({
                    'kind': token.kind.name,
                    'spelling': token.spelling,
                    'location': {
                        'line': token.location.line,
                        'column': token.location.column
                    }
                })
            
            # 2. å¾“æ¥ã®ASTæƒ…å ±ï¼ˆä¸‹ä½äº’æ›æ€§ï¼‰
            result["ast"] = cursor_to_dict(translation_unit.cursor)
            
            # 3. æ‹¡å¼µASTæƒ…å ±
            result["enhanced_ast"] = enhanced_cursor_to_dict(translation_unit.cursor)
            
            # 4. è¨ºæ–­æƒ…å ±
            for diag in translation_unit.diagnostics:
                result["diagnostics"].append({
                    'severity': diag.severity,
                    'spelling': diag.spelling,
                    'location': {
                        'line': diag.location.line,
                        'column': diag.location.column,
                        'file': diag.location.file.name if diag.location.file else None
                    },
                    'category_name': di
